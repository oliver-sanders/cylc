#!/usr/bin/env python
# THIS FILE IS PART OF THE CYLC SUITE ENGINE.
# Copyright (C) 2008-2017 NIWA
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
"""Orchestrates experiments to profile the performance of cylc at different
versions."""

import glob
import hashlib
import itertools
import json
import optparse
import os
import random
import re
import shutil
import sys
import tempfile
import time

# Write out floats to one decimal place only.
from json import encoder
encoder.FLOAT_REPR = lambda o: format(o, '.1f')

import cylc.profiling as prof
from cylc.profiling.analysis import (make_table, print_table, plot_results)
import cylc.profiling.git as git
from cylc.profiling.profile import profile

RUN_DOC = r"""cylc profile-battery [-e [EXPERIMENT ...]] [-v [VERSION ...]]

Run profiling experiments against different versions of cylc. A list of
experiments can be specified after the -e flag, if not provided the experiment
"complex" will be chosen. A list of versions to profile against can be
specified after the -v flag, if not provided the current version will be used.

Experiments are stored in dev/profile-experiments, user experiments can be
stored in .profiling/experiments. Experiments are specified without the file
extension, experiments in .profiling/ will be chosen before those in dev/.

    Note: See dev/profile-experiments/example for an experiment template with
          further details.

Versions are any valid git identifiers i.e. tags, branches, commits.

Profiling will save results to .profiling/results.json where they can be used
for future comparisons. To list profiling results run:
    * cylc profile-battery --ls  # list all results
    * cylc profile-battery --ls -e experiment  # list all results for
                                               # experiment "experiment".
    * cylc profile-battery --ls --delete -v  6.1.2  # Delete all results for
                                                    # version 6.1.2 (prompted).

If matplotlib and numpy are installed profiling generates plots which are
saved to .profiling/plots or presented in an interactive window using the -i
flag.

Results are stored along with a checksum for the experiment file. When an
experiment file is changed previous results are maintained, future results will
be stored separately. To copy results from an older version of an experiment
into those from the current one run:
    * cylc profile-battery --promote experiment@checksum

    Note: At present results cannot be analysed without the experiment file so
          old results must be "copied" in this way to be re-used.

The results output contain only a small number of metrics, to see a full list
of results use the --full option.

"""


def create_profile_directory():
    """Creates a directory for storing results and user experiments in."""
    profile_dir = os.path.join(prof.CYLC_DIR, prof.PROFILE_DIR_NAME)
    os.mkdir(profile_dir)
    os.mkdir(os.path.join(profile_dir, prof.PROFILE_PLOT_DIR_NAME))
    os.mkdir(os.path.join(profile_dir, prof.USER_EXPERIMENT_DIR_NAME))
    print 'creating', os.path.join(profile_dir, prof.PROFILE_FILE_NAME)
    with open(os.path.join(profile_dir, prof.PROFILE_FILE_NAME),
              'w+') as profile_file:
        profile_file.write('{}')


def parse_args():
    """Parse command line arguments for this script."""
    def multi_arg_callback(option, _, value, parser):
        """Allows an unkonwn number of arguments to be passed as an option."""
        assert value is None
        value = []
        for arg in parser.rargs:
            if arg[0] == '-':
                break
            value.append(arg)
        del parser.rargs[:len(value)]
        setattr(parser.values, option.dest, value)

    parser = optparse.OptionParser(RUN_DOC)
    parser.add_option('-e', '--experiments',
                      help='Specify list of experiments to run.',
                      dest='experiments', callback=multi_arg_callback,
                      action='callback')
    parser.add_option('-v', '--versions',
                      help='Specify cylc versions to profile. Git tags, ' +
                      'branches, commits are all valid.',
                      dest='versions', callback=multi_arg_callback,
                      action='callback')
    parser.add_option('--host', dest='host', type='str', default='localhost',
                      help='Specify the host to run the profiling on.')
    parser.add_option('-i', '--interactive', action='store_true',
                      help='Open any plots in interactive window rather '
                      'saving them to files.', default=False)
    parser.add_option('-p', '--no-plots', action='store_true', default=False,
                      help='Don\'t generate any plots.')
    parser.add_option('--ls', '--list-results', action='store_true',
                      default=False, help='List all stored results. ' +
                      'Experiments and versions to list can be specified ' +
                      'using --experiments and --versions.')
    parser.add_option('--delete', action='store_true', default=False,
                      help='Delete stored results (to be used in ' +
                      'combination with --list-results).')
    parser.add_option('--yes', '-y', action='store_true', default=False,
                      help='Answer yes to any user input')
    parser.add_option('--full-results', '--full', action='store_true',
                      default=False, help='Display all gathered metrics.')
    parser.add_option('--lobf-order', dest='lobf_order', help='The order (int)'
                      'of the line of best fit to be drawn. 0 for no lobf, '
                      '1 for linear, 2 for quadratic ect.', default=2,
                      type='int')
    parser.add_option('--promote', type='str', help='Promote results from an '
                      'older version of an experiment to the current version. '
                      'To be used when making non-functional changes to an '
                      'experiment.')
    parser.add_option('--test', action='store_true', default=False,
                      help='For development purposes, run experiment without '
                      'saving results and regardless of any prior runs.')
    parser.add_option('--markdown', action='store_true', default=False,
                      help='Output data tables in markdown format.')
    opts = parser.parse_args()[0]

    # Defaults for experiments and versions if we are not in list mode.
    if not (opts.ls or opts.delete):
        if not opts.experiments:
            opts.experiments = ["complex"]
        if not opts.versions:
            opts.versions = ["HEAD"]
    else:
        if not opts.experiments:
            opts.experiments = []
        if not opts.versions:
            opts.versions = []

    return opts


def get_results():
    """Return data from the results file."""
    if not os.path.exists(os.path.join(prof.CYLC_DIR, prof.PROFILE_DIR_NAME,
                                       prof.PROFILE_FILE_NAME)):
        # Profile file does not exist, create it.
        create_profile_directory()
        return {}
    else:
        # Profile file exists, git list of results contained.
        profile_file_path = os.path.join(prof.CYLC_DIR, prof.PROFILE_DIR_NAME,
                                         prof.PROFILE_FILE_NAME)
        with open(profile_file_path, 'r') as profile_file:
            try:
                profile_results = json.load(profile_file)
            except ValueError as exc:
                print exc
                sys.exit('ERROR: Could not read "%s". Check that it is valid'
                         ' JSON or delete the file.' % profile_file_path)
        return profile_results


def get_result_keys():
    """Return a list of (version_id, experiment_id,) tuples."""
    profile_results = get_results()
    result_keys = []
    for version_id, experiment_ids in profile_results.iteritems():
        result_keys.extend([(version_id, experiment_id) for experiment_id
                            in experiment_ids.keys()])
    return result_keys


def get_schedule(versions, experiments, test=False):
    """Determine which experiments to run with which versions.

    Return:
        tuple - (schedule, experiments_to_run)
            - schedule (dict) - Dictionary of cylc version ids containing lists
              of the experiments to run for each.
            - experiments_to_run (set) - Set of (version_id, experiment_id)
              tuples of the experiments to run.
    """
    # Generate list of (version_id, experiment_id) tuples for experiment to
    # run.
    experiment_keys = itertools.product(
        [version['id'] for version in versions],
        [experiment['id'] for experiment in experiments])
    # Acquire list of (version_id, experiment_id) tuples for experiments
    # already run.
    result_keys = get_result_keys()

    # Exclude any previously acquired results.
    if test:
        # Don't exclude experiments if in "test" mode.
        experiments_to_run = set(experiment_keys)
    else:
        experiments_to_run = set(experiment_keys) - set(result_keys)

    # Generate list of (version, experiment) tuples for the experiments to run.
    ret = []
    for version_id, experiment_id in experiments_to_run:
        for version in versions:
            if version['id'] == version_id:
                break
        else:
            raise Exception('Internal error.')
        for experiment in experiments:
            if experiment['id'] == experiment_id:
                break
        else:
            raise Exception('Internal error.')
        ret.append((version, experiment))
    return ret


def get_versions(version_names):
    """Produces a list of version objects from a list of cylc version names."""
    versions = []
    for version_name in version_names:
        version_id = git.describe(version_name)
        if version_id:
            versions.append({
                'name': version_name,
                'id': version_id
            })
        else:
            sys.exit('ERROR: cylc version "%s" not reccognised' % version_name)
    return versions


def get_checksum(file_path, chunk_size=4096):
    """Returns a hash of a file."""
    hash_ = hashlib.sha256()
    with open(file_path, 'rb') as file_:
        for chunk in iter(lambda: file_.read(chunk_size), b""):
            hash_.update(chunk)
        return hash_.hexdigest()[:15]


def load_experiment_config(experiment_file):
    """Returns a dictionary containing the contents of the experiment file."""
    with open(experiment_file, 'r') as file_:
        try:
            ret = json.load(file_)
        except ValueError as exc:
            sys.exit('ERROR: Invalid JSON in experiment file"{0}"\n{1}'.format(
                experiment_file, exc))

    # Prepend CYLC_DIR to suite definition paths if they aren't provided as
    # absolute paths.
    try:
        for run in ret['runs']:
            if not os.path.isabs(os.path.expanduser(run['suite dir'])):
                run['suite dir'] = os.path.join(prof.CYLC_DIR,
                                                run['suite dir'])
            run['suite dir'] = os.path.realpath(run['suite dir'])
    except KeyError as exc:
        print exc
        sys.exit('Error: Experiment definition not complete.')

    # Apply defaults.
    for run in ret['runs']:
        if 'repeats' not in run:
            run['repeats'] = 0
        if 'options' not in run:
            run['options'] = []
    if 'profile modes' not in ret:
        ret['profile modes'] = prof.DEFAULT_PROFILE_MODES
    if 'analysis' not in ret:
        ret['analysis'] = 'single'

    return ret


def install_experiments(experiments, install_dir):
    """Install experiment dependencies for use in profiling
    
    Args:
        experiments (iterable): Collection of "experiment" dictionaries
            representing each experiment to install.
        install_dir (str): The root profiling directory.
            - Suites will be installed in a "suites" subdirectory.
            - Global configuration files will be installed in a "globalrc"
              subdirectory.
    
    """
    install_sdir = os.path.join(install_dir, 'suites')
    os.mkdir(install_sdir)

    # Install suites.
    suite_dirs = {}
    dont_install = ['passphrase', 'ssl.cert', 'ssl.pem', 'suite.rc.processed']
    for experiment in experiments:
        # Loop over runs and install suites as necessary.
        for run in experiment['config']['runs']:
            sdir = os.path.realpath(run['suite dir'])
            if sdir in suite_dirs:
                # Update configuration to installed suite directory.
                run['suite dir'] = suite_dirs[sdir]
            else:
                # Install suite.
                new_sdir = os.path.join(install_sdir, str(random.random())[2:])
                print 'Installing suite: %s => %s' % (sdir, new_sdir)
                os.mkdir(new_sdir)
                for filepath in glob.glob(os.path.join(sdir, '*')):
                    # Don't install any suite-run files.
                    filename = os.path.basename(filepath)
                    if filename in dont_install:
                        continue
                    try:
                        shutil.copy(filepath, new_sdir)  # Copy file.
                    except IOError:
                        shutil.copytree(filepath,  # Copy directory.
                                        os.path.join(new_sdir, filename))
                suite_dirs[sdir] = new_sdir
                run['suite dir'] = new_sdir

    # Global config sourcing.
    os.mkdir(os.path.join(install_sdir, 'globalrc'))
    for experiment in experiments:
        for run in experiment['config']['runs']:
            if 'globalrc' in run:
                # Run requires a global.rc file - create one from provided
                # key=value pairs.
                string = ''
                for setting in run['globalrc']:
                    indent = 0
                    setting = re.split('[\[\]]+', setting.strip())
                    for part in setting[:-1]:  # Key hierarchy.
                        if not part:
                            continue
                        string += '%s%s%s%s\n' % (
                            '    ' * indent,
                            '[' * (indent + 1),
                            part,
                            ']' * (indent + 1)
                        )
                        indent += 1
                    string += '%s%s\n' % ('    ' * indent, setting[-1])
                # Write out global.rc file.
                hash_ = hashlib.sha256()
                hash_.update(string)
                dirname = os.path.join(install_sdir, 'globalrc',
                                       hash_.hexdigest()[:10])
                if not os.path.exists(dirname):
                    # If an identical globalrc has been written do nothing.
                    os.mkdir(dirname)
                    with open(os.path.join(dirname, 'global.rc'),
                              'w+') as globalrc_file:
                        globalrc_file.write(string)
                run['globalrc'] = dirname


def get_experiments(experiment_names):
    """Returns a dictionary of experiment names against experiment ids (which
    contain a checksum)."""
    experiments = []
    for experiment_name in experiment_names:
        file_name = experiment_name + '.json'
        # Look for experiment file in the users experiment directory.
        file_path = os.path.join(prof.CYLC_DIR, prof.PROFILE_DIR_NAME,
                                 prof.USER_EXPERIMENT_DIR_NAME, file_name)
        if not os.path.exists(file_path):
            # Look for experiment file in built-in experiment directory.
            file_path = os.path.join(prof.CYLC_DIR, prof.EXPERIMENTS_PATH,
                                     file_name)
            if not os.path.exists(file_path):
                # Could not find experiment file in either path. Exit!
                print 'ERROR: Could not find experiment file for "%s"' % (
                    experiment_name)
                experiments.append({'name': experiment_name,
                                    'id': 'Invalid',
                                    'file': None})
                continue
        config = load_experiment_config(file_path)
        experiments.append({
            'name': experiment_name,
            'id': '{0}@{1}'.format(experiment_name, get_checksum(file_path)),
            'file': file_path,
            'config': config
        })
    return experiments


def update_nested_dictionaries(old, new):
    """Merges entries from new into old (overwrites old with new in the event
    of a conflict."""
    old = old.copy()
    new = new.copy()
    for key, value in new.iteritems():
        if key in old:
            if type(value) is dict:
                old[key] = update_nested_dictionaries(old[key], new[key])
            else:
                old[key] = value
        else:
            old[key] = value
    return old


def append_new_results(results):
    """Append new profiling results to results file."""
    profile_file_path = os.path.join(prof.CYLC_DIR, prof.PROFILE_DIR_NAME,
                                     prof.PROFILE_FILE_NAME)
    try:
        with open(profile_file_path, 'r') as file_:
            previous_results = json.load(file_)
    except IOError as exc:
        if exc.errno == 2:
            previous_results = {}
        else:
            raise

    ret = update_nested_dictionaries(previous_results, results)
    os.remove(profile_file_path)
    with open(profile_file_path, 'w+') as file_:
        json.dump(ret, file_)


def delete_results(result_keys, interactive=False):
    """Delete results from the results file provided as a list of version_id,
    experiment_id tuples."""
    if interactive:
        usr = None
        while usr not in ['y', 'n']:
            usr = raw_input('Delete these results (y/n)? ')
        if usr != 'y':
            sys.exit(0)

    results = get_results()

    for version_id, experiment_id in result_keys:
        try:
            del results[version_id][experiment_id]
            if not results[version_id]:
                del results[version_id]
        except KeyError:
            pass

    profile_file_path = os.path.join(prof.CYLC_DIR, prof.PROFILE_DIR_NAME,
                                     prof.PROFILE_FILE_NAME)
    os.remove(profile_file_path)
    with open(profile_file_path, 'w+') as results_file:
        json.dump(results, results_file)


def install_cylc_versions(versions, install_dir):
    """Install cylc versions for use in profiling.
    
    Args:
        versions (iterable): Collection of "version" dictionaries representing
            each cylc version to install.
        install_dir (str): The root profiling directory.
            - Cylc versions will be installed in a "cylc" subdirectory.
            
    """
    os.mkdir(os.path.join(install_dir, 'cylc'))
    for version in versions:
        print 'Installing cylc: %s => %s' % (
            version['name'],
            os.path.join(install_dir, 'cylc', version['name']))
        git.archive_cylc_version(
                version['name'],
                prof.CYLC_DIR,
                os.path.join(install_dir, 'cylc', version['name']))


def run_schedule(schedule, host='localhost', test=False):
    """Run profiling using the provided schedule.

    Args:
        schedule (iterable): Collection of (version, experiment) tuples to
            profile.
        test (bool): Results will not be stored if test=True.

    """
    reg_base = 'profile-' + str(time.time()).replace('.', '')
    profiler_install_dir = os.path.join(os.path.expanduser('~'),
                                        'cylc-run',
                                        reg_base)
    os.mkdir(profiler_install_dir)
    if host != 'localhost':
        # TODO install profiler directory.
        pass

    # Install cylc versions as necessary.
    install_cylc_versions(dict((v['id'], v) for v, _ in schedule).values(),
                          profiler_install_dir)

    # Install experiments as necessary
    install_experiments(dict((e['id'], e) for _, e in schedule).values(),
                        profiler_install_dir)

    # Run profiling.
    results = profile(schedule, profiler_install_dir, reg_base, host=host)

    if results is False:
        # Profiling failed, keep install directory.
        return False
    else:
        # Profiling succeeded, tidy up.
        shutil.rmtree(profiler_install_dir)

    # Append results to results file.
    if not test:  # Don't store results in --test mode.
        append_new_results(results)

    return True


def run_analysis(experiments, versions, interactive=False,
                 quick_analysis=True, lobf_order=2, plot=True, markdown=False):
    """Runs analysis over the results already acquired.

    Args:
        versions (list): List of version dicts.
        experiments (list): List of experiment dicts.
        interactive (bool - optional): If True then interractive matplotlib
            windows will display rather than being rendered to a file.
        quick_analysis (bool - optional): If True then only a small set of the
            gathered metrics will be output.
        lobf_order (int - optional): The polynomial order to be used for
            generating the lines of best fit on all plots produced.
        plot (bool - optional): If True then plotting will be performed.

    """
    # Get results
    with open(os.path.join(prof.CYLC_DIR,
                           prof.PROFILE_DIR_NAME,
                           prof.PROFILE_FILE_NAME), 'r') as profile_file:
        full_results = json.load(profile_file)

    # Run analysis for each experiment requested.
    for experiment in experiments:
        plt_dir = False
        if not interactive:
            plt_dir = os.path.join(prof.CYLC_DIR,
                                   prof.PROFILE_DIR_NAME,
                                   prof.PROFILE_PLOT_DIR_NAME,
                                   experiment['name'] + '-' +
                                   str(int(time.time())))
            os.makedirs(plt_dir)

        # Print a table of results.
        print
        kwargs = {'transpose': not quick_analysis}
        if markdown:
            kwargs.update({'seperator': ' | ', 'border': '|', 'headers': True})
        print_table(
            make_table(full_results, versions, experiment,
                       quick_analysis=quick_analysis), **kwargs)
        print

        # Plot results.
        if not plot:
            continue
        plot_results(full_results, versions, experiment, plt_dir,
                     quick_analysis=quick_analysis, lobf_order=lobf_order)
        if plt_dir:
            print('Results for experiment "{exp}" have been written out to '
                  '"{dir}"'.format(exp=experiment['name'], dir=plt_dir))


def ls(exp_names, ver_names, delete=False):
    """List all results for the provided experiment and version names.

    Args:
        delete (bool - optional): If true the user is prompted whether to
            delete the selected results.

    """
    results = get_results()  # Get contents of results file.
    include = {}  # Dict of all results to list, exp_name: exp_id: [ver_id]
    all_versions = []  # List of all version ids contained in 'include'

    def include_result(experiment_name, experiment_id, version_id):
        if experiment_name not in include:
            include[experiment_name] = {}
        if experiment_id not in include[experiment_name]:
            include[experiment_name][experiment_id] = []
        include[experiment_name][experiment_id].append(version_id)
        if version_id not in all_versions:
            all_versions.append(version_id)

    if not exp_names and not ver_names:
        # No experiments or versions specified => list all results.
        for version_id in results:
            for experiment_id in results[version_id]:
                experiment_name = experiment_id.split('@')[0]
                include_result(experiment_name, experiment_id, version_id)
    else:
        # List only specified experiments and versions.
        version_ids = map(git.describe, ver_names)
        experiment_ids = set([name for name in exp_names if '@' in name])
        experiment_names = set(exp_names) - experiment_ids

        for version_id in results:
            if ver_names and version_id not in version_ids:
                continue
            for experiment_id in results[version_id]:
                experiment_name = experiment_id.split('@')[0]
                if (not exp_names or (experiment_name in experiment_names or
                                      experiment_id in experiment_ids)):
                    include_result(experiment_name, experiment_id, version_id)

    git.order_identifiers_by_date(all_versions)

    experiments = get_experiments(include.keys())
    current_experiment_ids = []
    for experiment in experiments:
        current_experiment_ids.append(experiment['id'])

    table = [['Experiment Name', 'Experiment ID', 'Version ID'],
             [None, None, None]]
    for experiment_name in sorted(include):
        table.append([experiment_name, None, None])
        for experiment_id in include[experiment_name]:
            if experiment_id in current_experiment_ids:
                table.append(['', '* ' + experiment_id, None])
            else:
                table.append(['', experiment_id, None])
            for version_id in all_versions:
                if version_id in include[experiment_name][experiment_id]:
                    table.append(['', '', version_id])

    print_table(table)

    if delete:
        filtered_keys = []
        for experiment_name in include:
            for experiment_id in include[experiment_name]:
                for version_id in include[experiment_name][experiment_id]:
                    filtered_keys.append((version_id, experiment_id,))
        delete_results(filtered_keys, interactive=True)


def promote(experiment_id, yes=False):
    """Promote any results for the provided experiment version to the current
    version."""
    if '@' not in experiment_id:
        sys.exit('A version must be supplied to promote an experiment e.g. '
                 'exp@a1b2c3d4e5')
    experiment_name, experiment_version = experiment_id.rsplit('@', 1)

    results = get_results()  # Get contents of results file.

    cur_exp_id = get_experiments([experiment_name])[0]['id']

    candidate_versions = []
    target_versions = []
    for version in results:
        for exp_id in results[version]:
            exp_name, exp_ver = exp_id.rsplit('@', 1)
            if exp_name != experiment_name:
                continue
            if exp_ver == experiment_version:
                candidate_versions.append(version)
            elif exp_id == cur_exp_id:
                target_versions.append(version)

    if not candidate_versions:
        sys.exit('There are no results for experiment "{experiment_id}".'
                 ''.format(experiment_id=experiment_id))
    ls([experiment_name], [])
    if target_versions:
        candidate_versions = [version for version in candidate_versions if
                              version not in target_versions]
        print
        print('Only the results for cylc versions not already profiled in '
              'the current experiment version will be promoted.')
    git.order_identifiers_by_date(candidate_versions)

    print
    print('Promote the following results for experiment "{name}" at version '
          '"{candidate}" to the current version "{target}":'.format(
              name=experiment_name,
              candidate=experiment_version,
              target=cur_exp_id.rsplit('@', 1)[1]
          ))
    print '\t', ' '.join(candidate_versions)

    if not yes:
        response = None
        while response not in ['y', 'n']:
            response = raw_input('Upgrade these versions? (y/n): ')
    if yes or response == 'y':
        # Promote results.
        try:
            for version in candidate_versions:
                results[version][cur_exp_id] = results[version][experiment_id]
        except KeyError as exc:
            print exc
            sys.exit('Unexpected error.')
        else:
            append_new_results(results)
        # Provide option to delete duplicates.
        ls([experiment_id], candidate_versions, delete=True)
    else:
        sys.exit('Aborted, not changes made.')


def main():
    """cylc profile-battery"""
    opts = parse_args()

    if not prof.IS_GIT_REPO:
        print >> sys.stderr, ('ERROR: profiling requires cylc to be a git '
                              'repository.')
        sys.exit(2)

    # Promote mode.
    if opts.promote:
        promote(opts.promote, opts.yes)
        sys.exit(0)

    # If in "list" mode print out results then exit.
    if opts.ls or opts.delete:
        ls(opts.experiments, opts.versions, delete=opts.delete)
        sys.exit(0)

    # Generate list of requested experiments and versions.
    experiments = get_experiments(opts.experiments)
    versions = get_versions(opts.versions)

    # Order versions.
    git.order_versions_by_date(versions)

    # Fail in the event that an experiment file cannot be found.
    if not all([experiment['file'] for experiment in experiments]):
        sys.exit('Experiment file(s) could not be loaded, profiling aborted.')

    # Run experiments as necessary.
    schedule = get_schedule(versions, experiments, test=opts.test)
    if schedule:
        if not run_schedule(schedule, opts.host, opts.test):
            sys.exit('Profiling failed.')

    # Don't run analysis if in "test" mode.
    if opts.test:
        sys.exit(0)

    # Run analysis
    run_analysis(experiments,
                 versions,
                 interactive=opts.interactive,
                 quick_analysis=not opts.full_results,
                 lobf_order=opts.lobf_order,
                 plot=not opts.no_plots,
                 markdown=opts.markdown)


if __name__ == '__main__':
    main()
